---
title: "Breast Cancer Biopsy Classification Project"
subtitle:  "Guy Leib (316311190), Shir Amit Fishbein (207640228), Nadav Klein (318865698)"
authors: Guy Leib, Shir Amit Fishbein, Nadav Klein
output: pdf_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r imports, include=FALSE}
library(ggplot2)
library(tidyverse)
library(patchwork)
library(dplyr) 
```
```{r}
#install.packages("GGally")
#install.packages("corrplot")
#install.packages("umap")
library(corrplot)
library(GGally)
library(umap)
library(plotly)
```


<Opening paragraph>

# The Data
Biopsy features for classification of 569 malignant (cancer) and benign (not cancer) breast masses.
Features were computationally extracted from digital images of fine needle aspirate biopsy slides.
## columns description
In each observation, 10 attributes were measured for *every cell* in the biopsy (see the list below).
Our data contain summery of those results and each row in the data contain only the mean, the standard error and the worst case among the cells (can be the larger or the most severe, depending the feature).
overall, the data contains 3*10 features and a label (column Y) that mention wherever the mass is malignant (M) or benign (B).
*list of the 10 measures:*
radius, texture, perimeter, area, smoothness, compactness, concavity, concave points, symmetry, fractal dimension.
radius: 	Nucleus radius (mean of distances from center to points on perimeter).
texture:	 Nucleus texture (standard deviation of grayscale values).
perimeter:	Nucleus perimeter.
area:	Nucleus area.
smoothness:	Smoothness of the tumor cells.
compactness:	 Nucleus compactness (perimeter^2/area - 1).
concavity:	Nucleus concavity (severity of concave portions of the contour).
concave_points:	Number of concave portions of the nucleus contour.
symmetry:	Nucleus Symmetry.
fractal_dimension: Nucleus fractal dimension ("coastline approximation" -1).


# Get started
## Upload and initial cleaning of the data
```{r load, message=FALSE, warning=FALSE, echo=FALSE}
brca <-read.csv("data//brca.csv")
```
```{r cleaning}
# remove the prefix "x." from column names
colnames(brca) <- gsub("^x\\.", "", colnames(brca))
colnames(brca)[which(names(brca) == "y")] <- "diagnosis"
# remove id column
brca<-brca[,-1]
# factorize the label
brca <- brca %>% mutate(diagnosis = if_else(diagnosis == "B", "Benign", "Malignant"))
brca$diagnosis <- as.factor(brca$diagnosis)
brca.x <- brca[,!(colnames(brca) %in% c("diagnosis"))]
colnames(brca)
```
## Show values range
```{r examine}
measures <- c("radius", "texture", "perimeter", "area", "smoothness", "compactness", "concavity", "concave_pts", "symmetry", "fractal_dim")
cat("Range of values in the numerical columns: \n")
for (prefix in measures) {
  # Find column names that start with the current prefix
  cat("-------", prefix, "-------\n")
  cat("\t\t\t min:\t\t max:\t\t mean:\n")
  prefix.mean <- paste0(prefix, "_mean")
  prefix.se <- paste0(prefix, "_se")
  prefix.worst <- paste0(prefix, "_worst")

  # Print the result
  cat("Mean:\t\t\t", round(min(brca[[prefix.mean]]), 2), "\t\t" , round(max(brca[[prefix.mean]]), 2), "\t\t", round(mean(brca[[prefix.mean]]) ,2), "\n")
  cat("Standard error:\t\t", round(min(brca[[prefix.se]]), 2), "\t\t" , round(max(brca[[prefix.se]]), 2), "\t\t", round(mean(brca[[prefix.se]]) ,2), "\n")
  cat("Worst:\t\t\t", round(min(brca[[prefix.worst]]), 2), "\t\t" , round(max(brca[[prefix.worst]]), 2), "\t\t", round(mean(brca[[prefix.worst]]) ,2), "\n")
}
cat("\n\nnumber of NAs in dataset: ",sum(is.na(brca)))
```

Above we see the ranges of the values in our data and that there are no missing values.
# Data cleaning
## Normalization
Because we have different ranges and we don't want that the scale of the feature will be a factor during the study we would like to normalize each column to values between 0 and 1 by preforming Min-Max normalization
```{r norm}
minmax <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
brca.x.normal <- as.data.frame(lapply(brca.x, minmax))
```
```{r show norm range}
for (prefix in measures) {
  # Find column names that start with the current prefix
  cat("-------", prefix, "-------\n")
  cat("\t\t\t min:\t\t max:\t\t mean:\n")
  prefix.mean <- paste0(prefix, "_mean")
  prefix.se <- paste0(prefix, "_se")
  prefix.worst <- paste0(prefix, "_worst")

  # Print the result
  cat("Mean:\t\t\t", round(min(brca.x.normal[[prefix.mean]]), 2), "\t\t" , round(max(brca.x.normal[[prefix.mean]]), 2), "\t\t", round(mean(brca.x.normal[[prefix.mean]]) ,2), "\n")
  cat("Standard error:\t\t", round(min(brca.x.normal[[prefix.se]]), 2), "\t\t" , round(max(brca.x.normal[[prefix.se]]), 2), "\t\t", round(mean(brca.x.normal[[prefix.se]]) ,2), "\n")
  cat("Worst:\t\t\t", round(min(brca.x.normal[[prefix.worst]]), 2), "\t\t" , round(max(brca.x.normal[[prefix.worst]]), 2), "\t\t", round(mean(brca.x.normal[[prefix.worst]]) ,2), "\n")
}
```

# Exploratory Data Analysis
## Balance
First, we want to see if the labels are balanced:
```{r piechart}
# Create a data frame from the frequency counts
y.freq <- data.frame(y.names = names(table(brca$diagnosis)), count = table(brca$diagnosis))

# Create the pie chart using ggplot2
ggplot(y.freq, aes(x = "", y = count.Freq, fill = y.names)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  labs(fill = "Diagnosis") +
  theme_void() +
  geom_text(aes(label = count.Freq), position = position_stack(vjust = 0.5))
```
We can see that the data doesn't contain significant bias toward one of the labels.
it is possible that it could effect on the results but as for now, we don't think it is necessary to change something.

## distributions differences
We want to explore if we can see visually how the measures are related to the diagnosis,
we create box plots to each aspect of each measure for both labels - Benign and Malignant.
```{r mean plot}
box_df <- as_tibble(brca.x.normal) %>%
  select(ends_with("_mean")) %>%
  rename_all(~ str_replace_all(., "_mean", "")) %>%
  mutate(brca["diagnosis"]) %>%
  pivot_longer(col = -diagnosis, names_to = "features", values_to = "value")
p.mean <- ggplot(box_df,
       aes(factor(features,levels = measures),
           value, fill = diagnosis)) +
  geom_boxplot() +
  scale_fill_manual(values = c("#75c731", "#0488cf")) +
  labs(x = "explanatory variables", y = "standardized value") +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(size = 7))
p.mean + plot_annotation(title = "Mean values distribution")
```
```{r se plot}
box_df <- as_tibble(brca.x.normal) %>%
  select(ends_with("_se")) %>%
  rename_all(~ str_replace_all(., "_se", "")) %>%
  mutate(brca["diagnosis"]) %>%
  pivot_longer(col = -diagnosis, names_to = "features", values_to = "value")
p.mean <- ggplot(box_df,
       aes(factor(features,levels = measures),
           value, fill = diagnosis)) +
  geom_boxplot() +
  scale_fill_manual(values = c("#75c731", "#0488cf")) +
  labs(x = "explanatory variables", y = "standardized value") +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(size = 7))
p.mean + plot_annotation(title = "Standard error values distribution")
```
```{r worst plot}
box_df <- as_tibble(brca.x.normal) %>%
  select(ends_with("_worst")) %>%
  rename_all(~ str_replace_all(., "_worst", "")) %>%
  mutate(brca["diagnosis"]) %>%
  pivot_longer(col = -diagnosis, names_to = "features", values_to = "value")
p.mean <- ggplot(box_df,
       aes(factor(features,levels = measures),
           value, fill = diagnosis)) +
  geom_boxplot() +
  scale_fill_manual(values = c("#75c731", "#0488cf")) +
  labs(x = "explanatory variables", y = "standardized value") +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(size = 7))
p.mean + plot_annotation(title = "Worst values distribution")
```



# Feture selection
Because the nature of our data, having 3 aspects of every feature, there might be biases while applying VM models using all the features, where there can be duplicates in the trends between then (e.g correlation trend between ). moreover, the "worst" columns are often in correlation with the "mean" and the "se" of the same measure. [see supplement]
To overcome this, we apply PCA on each triplet of "mean", "se" and "worst" and create new data-frame with columns of the PCs (until 95% contribution of variables) instead of the whole triplets.
In addition, even between the different measures, we can find duplicates:
The radius of a cell has strong correlation to it's perimeter and area.
here we see correlation matrix of those features:
```{r}
mesures.shape <- c("radius", "perimeter", "area")
measures <- c("texture","smoothness", "compactness", "concavity", "concave_pts", "symmetry", "fractal_dim")
shape <- c()
for (prefix in mesures.shape) {
  # Find column names that start with the current prefix
  shape <- append(shape,paste0(prefix, "_mean"))
  shape <- append(shape,paste0(prefix, "_se"))
  shape <- append(shape,paste0(prefix, "_worst"))
}
brca.subset <- brca.x.normal[,shape]
cor(brca.subset) %>%
corrplot(method = "square", tl.col = "black", tl.srt = 45,
         sig.level = 0.05)
```

```{r}
brca.reduce <- data.frame(brca[,c('diagnosis')])
colnames(brca.reduce) <- c("diagnosis")
brca.reduce$shape_pc1 <- pca$x[,1]
brca.reduce$shape_pc2 <- pca$x[,2]
```
```{r}
cor(brca.reduce) %>% corrplot(method = "square", tl.col = "black", tl.srt = 45, sig.level = 0.05)
```

### supplementary Plots:
correlation between triplets of "mean", "se" and "worst".
```{r corr_triplets}
for (prefix in measures) {
  # Find column names that start with the current prefix
  prefix.mean <- paste0(prefix, "_mean")
  prefix.se <- paste0(prefix, "_se")
  prefix.worst <- paste0(prefix, "_worst")
  brca.subset <- brca.x.normal[,c(prefix.mean, prefix.se, prefix.worst)]
  cor(brca.subset) %>% corrplot(method = "square", tl.col = "black", tl.srt = 45, sig.level = 0.05)
}
```


```{r}
for (prefix in measures) {
  # Find column names that start with the current prefix
  prefix.mean <- paste0(prefix, "_mean")
  prefix.se <- paste0(prefix, "_se")
  prefix.worst <- paste0(prefix, "_worst")
  brca.subset <- brca.x.normal[,c(prefix.mean, prefix.se, prefix.worst)]
  cat("--------", prefix, "--------\n")
  pcs <- prcomp(brca.subset)
  cat(prefix, ": PC1 Cumulative Proportion of Variance:", (pcs$sdev[1]^2/sum(pcs$sdev^2)), "\n")
  brca.reduce[[paste0(prefix, "_pc1")]] <- pcs$x[,1]
  if ((pcs$sdev[1]^2/sum(pcs$sdev^2)) < 0.9) {
    cat(prefix, ": PC2 Cumulative Proportion of Variance:", (sum(pcs$sdev[1:2]^2/sum(pcs$sdev^2))), "\n")
    brca.reduce[[paste0(prefix, "_pc2")]] <- pcs$x[,2]
     if ((sum(pcs$sdev[1:2]^2/sum(pcs$sdev^2))) < 0.9) {
      cat(prefix, ": PC3 Cumulative Proportion of Variance:", (sum(pcs$sdev^2/sum(pcs$sdev^2))), "\n")
      brca.reduce[[paste0(prefix, "_pc3")]] <- pcs$x[,3]
      }
  }
}
brca.x.reduce <- brca.reduce[,!(colnames(brca.reduce) %in% c("diagnosis"))]
```
```{r corr after pca}
cor(brca.x.reduce) %>% corrplot(method = "square", tl.col = "black", tl.srt = 45, sig.level = 0.05)
```
```{r corr before pca}
cor(brca.x.normal) %>% corrplot(method = "square", tl.col = "black", tl.srt = 45, sig.level = 0.05)
```

For Guy and Shir:
the variable brca contains the whole dataframe in the raw shape
the variable brca.x contains only the numerical features (no diagnosis)
brca.x.normal is brca after min-max normalization
brca.reduce and brca.x.reduce are the dataframes after dimantionality reduction
pls try every ML algorithm on both brca (or brca.x.normal if you want it noramlized) and brca.reduce
afterward we will see if the dimentionality reduction did helped.







