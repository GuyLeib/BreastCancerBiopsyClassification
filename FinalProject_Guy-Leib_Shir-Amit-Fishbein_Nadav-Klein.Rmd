---
title: "Breast Cancer Biopsy Classification Project"
subtitle:  "Guy Leib (316311190), Shir Amit Fishbein (207640228), Nadav Klein (318865698)"
authors: Guy Leib, Shir Amit Fishbein, Nadav Klein
output: pdf_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r imports, include=FALSE}
library(ggplot2)
library(tidyverse)
library(dplyr) 
```
```{r}
#install.packages("GGally")
#install.packages("corrplot")
#install.packages("umap")
library(corrplot)
library(GGally)
library(umap)
library(plotly)
```


<Opening paragraph>

# The Data
Biopsy features for classification of 569 malignant (cancer) and benign (not cancer) breast masses.
Features were computationally extracted from digital images of fine needle aspirate biopsy slides.
## columns description
In each observation, 10 attributes were measured for *every cell* in the biopsy (see the list below).
Our data contain summery of those results and each row in the data contain only the mean, the standard error and the worst case among the cells (can be the larger or the most severe, depending the feature).
overall, the data contains 3*10 features and a label (column Y) that mention wherever the mass is malignant (M) or benign (B).
*list of the 10 measures:*
radius, texture, perimeter, area, smoothness, compactness, concavity, concave points, symmetry, fractal dimension.
radius: 	Radius of the tumor cells
texture:	Texture of the tumor cells
perimeter:	Perimeter of the tumor cells
area:	Area of the tumor cells
smoothness:	Smoothness of the tumor cells
compactness:	Compactness of the tumor cells
concavity:	Concavity of the tumor cells
concave_points:	Number of concave portions of the contour of the tumor cells
symmetry:	Symmetry of the tumor cells
fractal_dimension:    "Coastline approximation" of the tumor cells


# Get started
## Upload and initial cleaning of the data
```{r load, message=FALSE, warning=FALSE, echo=FALSE}
brca <-read.csv("data//brca.csv")
```
```{r cleaning}
# remove the prefix "x." from column names
colnames(brca) <- gsub("^x\\.", "", colnames(brca))
colnames(brca)[which(names(brca) == "y")] <- "diagnosis"
# remove id column
brca<-brca[,-1]
# factorize the label
brca <- brca %>% mutate(diagnosis = if_else(diagnosis == "B", "Benign", "Malignant"))
brca$diagnosis <- as.factor(brca$diagnosis)
brca.x <- brca[,!(colnames(brca) %in% c("diagnosis"))]
colnames(brca)
```
## Show values range
```{r examine}
measures <- c("radius", "texture", "perimeter", "area", "smoothness", "compactness", "concavity", "concave_pts", "symmetry", "fractal_dim")
cat("Range of values in the numerical columns: \n")
for (prefix in measures) {
  # Find column names that start with the current prefix
  cat("-------", prefix, "-------\n")
  cat("\t\t\t min:\t\t max:\t\t mean:\n")
  prefix.mean <- paste0(prefix, "_mean")
  prefix.se <- paste0(prefix, "_se")
  prefix.worst <- paste0(prefix, "_worst")

  # Print the result
  cat("Mean:\t\t\t", round(min(brca[[prefix.mean]]), 2), "\t\t" , round(max(brca[[prefix.mean]]), 2), "\t\t", round(mean(brca[[prefix.mean]]) ,2), "\n")
  cat("Standard error:\t\t", round(min(brca[[prefix.se]]), 2), "\t\t" , round(max(brca[[prefix.se]]), 2), "\t\t", round(mean(brca[[prefix.se]]) ,2), "\n")
  cat("Worst:\t\t\t", round(min(brca[[prefix.worst]]), 2), "\t\t" , round(max(brca[[prefix.worst]]), 2), "\t\t", round(mean(brca[[prefix.worst]]) ,2), "\n")
}
cat("\n\nnumber of NAs in dataset: ",sum(is.na(brca)))
```

Above we see the ranges of the values in our data and that there are no missing values.
# Data cleaning
## Normalization
Because we have different ranges and we don't want that the scale of the feature will be a factor during the study we would like to normalize each column to values between 0 and 1 by preforming Min-Max normalization
```{r norm}
minmax <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
brca.x.normal <- as.data.frame(lapply(brca.x, minmax))
```
```{r show norm range}
for (prefix in measures) {
  # Find column names that start with the current prefix
  cat("-------", prefix, "-------\n")
  cat("\t\t\t min:\t\t max:\t\t mean:\n")
  prefix.mean <- paste0(prefix, "_mean")
  prefix.se <- paste0(prefix, "_se")
  prefix.worst <- paste0(prefix, "_worst")

  # Print the result
  cat("Mean:\t\t\t", round(min(brca.x.normal[[prefix.mean]]), 2), "\t\t" , round(max(brca.x.normal[[prefix.mean]]), 2), "\t\t", round(mean(brca.x.normal[[prefix.mean]]) ,2), "\n")
  cat("Standard error:\t\t", round(min(brca.x.normal[[prefix.se]]), 2), "\t\t" , round(max(brca.x.normal[[prefix.se]]), 2), "\t\t", round(mean(brca.x.normal[[prefix.se]]) ,2), "\n")
  cat("Worst:\t\t\t", round(min(brca.x.normal[[prefix.worst]]), 2), "\t\t" , round(max(brca.x.normal[[prefix.worst]]), 2), "\t\t", round(mean(brca.x.normal[[prefix.worst]]) ,2), "\n")
}
```

# Exploratory Data Analysis
```{r piechart}
# Create a data frame from the frequency counts
y.freq <- data.frame(y.names = names(table(brca$diagnosis)), count = table(brca$diagnosis))

# Create the pie chart using ggplot2
ggplot(y.freq, aes(x = "", y = count.Freq, fill = y.names)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  labs(fill = "Diagnosis") +
  theme_void() +
  geom_text(aes(label = count.Freq), position = position_stack(vjust = 0.5))
```
# Feture selection 
Because the nature of our data, having 3 aspects of every feature, there might be biases while applying VM models using all the features, where there can be duplicates in the trends between then (e.g correlation trend between ). moreover, the "worst" columns are often in correlation with the "mean" and the "se" of the same measure. [see supplement]
To overcome this, we apply PCA on each triplet of "mean", "se" and "worst" and create new data-frame with columns of the PCs (until 95% contribution of variables) instead of the whole triplets.
In addition, even between the different measures, we can find duplicates:
The radius of a cell has strong correlation to it's perimeter and area.
here we see correlation matrix of those features:
```{r}
mesures.geom <- c("radius", "perimeter", "area")
measures <- c("texture","smoothness", "compactness", "concavity", "concave_pts", "symmetry", "fractal_dim")
geo <- c()
for (prefix in mesures.geom) {
  # Find column names that start with the current prefix
  geo <- append(geo,paste0(prefix, "_mean"))
  geo <- append(geo,paste0(prefix, "_se"))
  geo <- append(geo,paste0(prefix, "_worst"))
}
brca.subset <- brca.x.normal[,geo]
cor(brca.subset) %>%
corrplot(method = "square", tl.col = "black", tl.srt = 45,
         sig.level = 0.05)
```
```{r}
pca <- prcomp(brca.subset)
summary(pca)

pca.plot <- data.frame(
  PC1 = pca$x[, 1],
  PC2 = pca$x[, 2],
  label = brca$diagnosis)
ggplot(pca.plot, aes(x = PC1, y = PC2, col = label)) +
  geom_point()
```

```{r}
brca.reduce <- data.frame(brca[,c('diagnosis')])
colnames(brca.reduce) <- c("diagnosis")
brca.reduce$geom_pc1 <- pca$x[,1]
brca.reduce$geom_pc2 <- pca$x[,2]
```

### supplementary Plots:
correlation between triplets of "mean", "se" and "worst".
```{r corr_triplets}
for (prefix in measures) {
  # Find column names that start with the current prefix
  prefix.mean <- paste0(prefix, "_mean")
  prefix.se <- paste0(prefix, "_se")
  prefix.worst <- paste0(prefix, "_worst")
  brca.subset <- brca[,c(prefix.mean, prefix.se, prefix.worst)]
  cor(brca.subset) %>% corrplot(method = "square", tl.col = "black", tl.srt = 45, sig.level = 0.05)
}
```


```{r}
for (prefix in measures) {
  # Find column names that start with the current prefix
  prefix.mean <- paste0(prefix, "_mean")
  prefix.se <- paste0(prefix, "_se")
  prefix.worst <- paste0(prefix, "_worst")
  brca.subset <- brca.x.normal[,c(prefix.mean, prefix.se, prefix.worst)]
  cat("--------", prefix, "--------\n")
  pcs <- prcomp(brca.subset)
  cat(prefix, ": PC1 Cumulative Proportion of Variance:", (pcs$sdev[1]^2/sum(pcs$sdev^2)), "\n")
  brca.reduce[[paste0(prefix, "_pc1")]] <- pcs$x[,1]
  if ((pcs$sdev[1]^2/sum(pcs$sdev^2)) < 0.5) {
    cat(prefix, ": PC2 Cumulative Proportion of Variance:", (sum(pcs$sdev[1:2]^2/sum(pcs$sdev^2))), "\n")
    brca.reduce[[paste0(prefix, "_pc2")]] <- pcs$x[,2]
     if ((sum(pcs$sdev[1:2]^2/sum(pcs$sdev^2))) < 0.5) {
      cat(prefix, ": PC3 Cumulative Proportion of Variance:", (sum(pcs$sdev^2/sum(pcs$sdev^2))), "\n")
      brca.reduce[[paste0(prefix, "_pc3")]] <- pcs$x[,3]
      }
  }
}
```
```{r corr after pca}
cor(brca.reduce[,!(colnames(brca.reduce) %in% c("diagnosis"))]) %>% corrplot(method = "square", tl.col = "black", tl.srt = 45, sig.level = 0.05)
```
```{r corr_triplets}
brca.pca.cor <- cor(brca.reduce[,!(colnames(brca.reduce) %in% c("diagnosis"))])
indices <- which(brca.pca.cor > 0.8, arr.ind = TRUE)
indices.names <- indices
indices.names[, 1] <- rownames(brca.pca.cor)[indices[, 1]]
indices.names[, 2] <- colnames(brca.pca.cor)[indices[, 2]]


# Print the extracted row and column names
indices.names[(indices.names[, 1] != indices.names[, 2]),]
```

```{r, fig.width = 10}
cor(brca.x.normal) %>% corrplot(method = "square", tl.col = "black", tl.srt = 45, sig.level = 0.05)

```


```{r}
mesures.geom <- c("radius", "perimeter", "area")
measures <- c("texture","smoothness", "compactness", "concavity", "concave_pts", "symmetry", "fractal_dim")
# create the min/max normalization function:

brca.pca <- data.frame(brca[,c('y')])
colnames(brca.pca) <- c("y")
for (prefix in measures) {
  # Find column names that start with the current prefix
  prefix.mean <- paste0(prefix, "_mean")
  prefix.se <- paste0(prefix, "_se")
  prefix.worst <- paste0(prefix, "_worst")
  brca.subset <- brca[,c(prefix.mean, prefix.se, prefix.worst)]
  #normalize the data without the classification column
  brca.subset <- as.data.frame(lapply(brca.subset, minmax))
  cor(brca.subset) %>%
  corrplot(method = "square", tl.col = "black", tl.srt = 45,
           sig.level = 0.05)
  cat("--------", prefix, "--------\n")
  pcs <- prcomp(brca.subset)
  cat(prefix, ": PC1 Cumulative Proportion of Variance:", (pcs$sdev[1]^2/sum(pcs$sdev^2)), "\n")
  brca.pca[[paste0(prefix, "_pc1")]] <- pcs$x[,1]
  if ((pcs$sdev[1]^2/sum(pcs$sdev^2)) < 0.95) {
    cat(prefix, ": PC2 Cumulative Proportion of Variance:", (sum(pcs$sdev[1:2]^2/sum(pcs$sdev^2))), "\n")
    brca.pca[[paste0(prefix, "_pc2")]] <- pcs$x[,2]
     if ((sum(pcs$sdev[1:2]^2/sum(pcs$sdev^2))) < 0.95) {
      cat(prefix, ": PC3 Cumulative Proportion of Variance:", (sum(pcs$sdev^2/sum(pcs$sdev^2))), "\n")
      brca.pca[[paste0(prefix, "_pc3")]] <- pcs$x[,3]
      }
  }
}
```


```{r}
measures <- c("radius", "perimeter", "area")
# create the min/max normalization function:
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
brca.pca <- data.frame(brca[,c('y')])
colnames(brca.pca) <- c("y")
```
```{r}
brca.pca.cor <- cor(brca.pca[,!(colnames(brca.pca) %in% c("y"))]) > 0.9
cor(brca.pca[,!(colnames(brca.pca) %in% c("y"))]) %>%
  corrplot(method = "square", tl.col = "black", tl.srt = 45,
           sig.level = 0.05)
# Extract row and column names based on condition
indices <- which(abs(brca.pca.cor) > 0.9, arr.ind = TRUE)
indices.names <- indices
indices.names[, 1] <- rownames(brca.pca.cor)[indices[, 1]]
indices.names[, 2] <- colnames(brca.pca.cor)[indices[, 2]]


# Print the extracted row and column names
indices.names[(indices.names[, 1] != indices.names[, 2]),]
```


```{r}
measures.groups <- c("_mean", "_se", "_worst")
```
```{r}
cor(brca[,!(colnames(brca) %in% c("y"))] , method = "spearman") %>%
  corrplot(method = "square", tl.col = "black", tl.srt = 45,
           sig.level = 0.05)
```
```{r}
# Calculate the correlation matrix
cor_matrix <- cor(brca[,-(ncol(brca))] , method = "spearman")

# Find column pairs with correlation higher than 0.9
high_corr_pairs <- which(upper.tri(cor_matrix) & abs(cor_matrix) > 0.8, arr.ind = TRUE)

# Remove one of the columns from each high correlation pair
to_remove <- c()
for (i in 1:nrow(high_corr_pairs)) {
  col1 <- high_corr_pairs[i, 1]
  col2 <- high_corr_pairs[i, 2]
  
  if (!(col1 %in% to_remove)) {
    to_remove <- c(to_remove, col2)
  }
}

# Remove the columns from the brca dataframe
brca.noncorr <- brca[, -to_remove]
colnames(brca.noncorr)
```
```{r}
cor(brca.noncorr[,-(ncol(brca.noncorr))] , method = "spearman") %>%
  corrplot(method = "square", tl.col = "black", tl.srt = 45,
           sig.level = 0.05)
```
```{r}
((brca.x$perimeter_mean * brca.x$perimeter_mean) / (brca.x$area_mean )) - brca.x$compactness_mean
```
```{r}
mesures.concavity <- c("compactness", "concavity")
geo <- c()
for (prefix in mesures.concavity) {
  # Find column names that start with the current prefix
  geo <- append(geo,paste0(prefix, "_mean"))
  geo <- append(geo,paste0(prefix, "_se"))
  geo <- append(geo,paste0(prefix, "_worst"))
}
brca.subset <- brca.x.normal[,geo]
#normalize the data without the classification column
brca.subset <- as.data.frame(lapply(brca.subset, normalize))
cor(brca.subset) %>%
corrplot(method = "square", tl.col = "black", tl.srt = 45,
         sig.level = 0.05)
pca <- prcomp(brca.subset)
summary(pca)

pca.plot <- data.frame(
  PC1 = pca$x[, 1],
  PC2 = pca$x[, 2],
  label = brca$diagnosis)
ggplot(pca.plot, aes(x = PC1, y = PC2, col = label)) +
  geom_point()
```









